{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd \n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import utils\n",
    "from torchvision.io import read_image\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.ops import box_convert\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g:\\\\Work\\\\BMW\\\\Workbench\\\\data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = os.path.join(os.getcwd(), \"data\" )\n",
    "test_dir = os.path.join(root_dir, \"data2\")\n",
    "root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Detection Class\n",
    "class ImageDetection(Dataset):\n",
    "    def __init__(self, root_dir, width, height, transforms=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transforms = transforms\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "\n",
    "        self.folders = os.listdir(root_dir)\n",
    "        self.images = []\n",
    "        self.json_data = []\n",
    "        \n",
    "\n",
    "        for folder in self.folders:\n",
    "            folder_path = os.path.join(root_dir, folder)\n",
    "            image_folder = os.path.join(folder_path, \"images\")\n",
    "            json_folder = os.path.join(folder_path, \"labels\", \"json\")\n",
    "\n",
    "            for file in os.listdir(image_folder):\n",
    "                file_path = os.path.join(image_folder, file)\n",
    "                self.images.append((file_path, folder))\n",
    "            \n",
    "            for file in os.listdir(json_folder):\n",
    "                file_path = os.path.join(json_folder, file)\n",
    "                self.json_data.append((file_path, folder))\n",
    "\n",
    "    def images(self):\n",
    "        return self.json_data\n",
    "\n",
    "    def load_image(self, idx):\n",
    "        img_file = self.images[idx][0]\n",
    "        image = read_image(img_file)\n",
    "        return Image.open(img_file).convert(\"RGB\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_file = self.images[idx][0]\n",
    "        json_file = self.json_data[idx][0]\n",
    "\n",
    "        #reading the images and coverting them to correct size and color\n",
    "        img = cv2.imread(img_file)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        img_res = cv2.resize(img_rgb, (self.width, self.height), cv2.INTER_AREA)\n",
    "        img_res /= 255.0\n",
    "\n",
    "       \n",
    "        df1 = pd.read_json(json_file)\n",
    "       \n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        pen_y  =  img_res.shape[0] / img.shape[0] \n",
    "        pen_x =  img_res.shape[1]  /img.shape[1] \n",
    "\n",
    "        for i in range(len(df1)):\n",
    "            labels.append(df1[\"ObjectClassId\"][i])\n",
    "            x1 = df1[\"Left\"][i] *pen_x\n",
    "            y1 = df1[\"Top\"][i] * pen_y\n",
    "            x2 = df1[\"Right\"][i] * pen_x\n",
    "            y2 = df1[\"Bottom\"][i] * pen_y\n",
    "\n",
    "            boxes.append([x1, y1, x2, y2])\n",
    "            \n",
    "        # print(\"act boxes\", boxes)\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "            \n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = torch.tensor([idx])\n",
    "        target[\"area\"] = area\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(image = img_res, bboxes = target[\"boxes\"], labels = labels)\n",
    "            img_res = sample[\"image\"]\n",
    "            target[\"boxes\"] = torch.Tensor(sample[\"bboxes\"])\n",
    "\n",
    "       \n",
    "\n",
    "        print(\"target\", target)\n",
    "        \n",
    "        return img_res, target\n",
    "        \n",
    "# data_set.__getitem__(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "def plot_image_and_boxes(image, target):\n",
    "    print(\"Image Shape is Now \" , image.shape)\n",
    "    fig, a = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(5, 5)\n",
    "    a.imshow(image)\n",
    "    # print(\"target boxes\" , target[\"boxes\"])\n",
    "    for box in target[\"boxes\"]:\n",
    "        x, y , width, height  = box[0], box[1], box[2] - box[0], box[3] - box[1]\n",
    "        rect  = patches.Rectangle((x, y), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        a.add_patch(rect)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# image, target = data_set[1]\n",
    "# plot_image_and_boxes(image, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    if train:\n",
    "        return A.Compose([\n",
    "            A.Resize(),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "    else:\n",
    "        return A.Compose([\n",
    "            A.Resize(),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_set = ImageDetection(root_dir, width=280, height=240, transforms=None)\n",
    "\n",
    "print(\"Length of data set is \" , len(data_set))\n",
    "\n",
    "# data_set_test = ImageDetection(test_dir, width=280, height=240, transforms=None)\n",
    "\n",
    "# torch.manual_seed(1)\n",
    "# indices = torch.randperm(len(data_set)).tolist()\n",
    "\n",
    "# test_split = 0.25\n",
    "# t_size = int(len(data_set) * test_split)\n",
    "\n",
    "\n",
    "train_data_set, test_data_set = torch.utils.data.random_split(data_set, [int(len(data_set)*0.75), int(len(data_set)*0.25)+1])\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "NUM_WORKERS = 0\n",
    "train_image_data_loader = DataLoader(dataset=train_data_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "test_image_data_loader = DataLoader(dataset=test_data_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS )\n",
    "\n",
    "image, target = train_data_set[1]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for idx, batch in enumerate(train_image_data_loader):\n",
    "\n",
    "    print(batch[1])\n",
    "    \n",
    "    if idx == 500:\n",
    "        break\n",
    "\n",
    "\n",
    "# plot_image_and_boxes(image, target)\n",
    "\n",
    "# len(train_image_data_loader), len(test_image_data_loader)\n",
    "\n",
    "\n",
    "# for batch in data_set:\n",
    "#     print(batch)\n",
    "\n",
    "#     break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-trained model\n",
    "def get_object_detection_model(num_classes):\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn()\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "model = get_object_detection_model(num_classes)\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch(model, optimizer, train_image_data_loader, device, epoch, print_freq=10)\n",
    "    lr_scheduler.step()\n",
    "    evaluate(model, test_image_data_loader, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
