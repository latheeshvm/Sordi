{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "folder_name_image_name_id.jpg\n",
    "csv_columns = id,image_name,image_width, image_height, object_class_id,object_class_name,bbox_left, bbox_top, bbox_right, bbox_bottom\n",
    "\n",
    "\n",
    "### operations to be done\n",
    "- rename the file\n",
    "- add the data to csv file\n",
    "- move it to data folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directory -- Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "project_directory =  os.getcwd()\n",
    "data_folder = project_directory + os.sep + 'data'\n",
    "isExist = os.path.exists(data_folder)\n",
    "if not isExist:\n",
    "   os.makedirs(data_folder)\n",
    "csv_file_path = project_directory + os.sep + \"data/image_info.csv\"\n",
    "un_processed_data_path =  project_directory + os.sep + \"data-unprocessed\"\n",
    "un_processed_directories = os.listdir(un_processed_data_path)\n",
    "\n",
    "destination_directory = project_directory + os.sep + \"data\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {\n",
    "    \"id\":[],\n",
    "    \"image_name\":[],\n",
    "    \"image_width\":[],\n",
    "    \"image_height\":[],\n",
    "    \"object_class_id\":[],\n",
    "    \"object_class_name\":[],\n",
    "    \"bbox_left\":[],\n",
    "    \"bbox_top\":[],\n",
    "    \"bbox_right\":[],\n",
    "    \"bbox_bottom\":[],\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(header)\n",
    "# df.to_csv(csv_file_path)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data to csv file\n",
    "\n",
    "# data_append = {\n",
    "#     \"id\":[1],\n",
    "#     \"image_name\":[\"test.jpg\"],\n",
    "#     \"image_width\":[1989],\n",
    "#     \"image_height\":[1211],\n",
    "#     \"object_class_id\":[1001],\n",
    "#     \"object_class_name\":[\"byclce\"],\n",
    "#     \"bbox_left\":[12],\n",
    "#     \"bbox_top\":[12],\n",
    "#     \"bbox_right\":[21],\n",
    "#     \"bbox_bottom\":[21],\n",
    "# }\n",
    "\n",
    "# data_append2 = {\n",
    "#     \"id\":[2],\n",
    "#     \"image_name\":[\"teassst.jpg\"],\n",
    "#     \"image_width\":[1989],\n",
    "#     \"image_height\":[1211],\n",
    "#     \"object_class_id\":[1001],\n",
    "#     \"object_class_name\":[\"byclce\"],\n",
    "#     \"bbox_left\":[12],\n",
    "#     \"bbox_top\":[12],\n",
    "#     \"bbox_right\":[21],\n",
    "#     \"bbox_bottom\":[21],\n",
    "# }\n",
    "\n",
    "# df2 = pd.DataFrame(data_append)\n",
    "# df4 = pd.DataFrame(data_append2)\n",
    "# df3 = pd.concat([df, df2, df4], ignore_index=True)\n",
    "# df3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connected_data_generator(un_processed_directories):\n",
    "    unp_data = []\n",
    "\n",
    "    for dir in un_processed_directories:\n",
    "\n",
    "        labels =  os.listdir(un_processed_data_path + os.sep + dir + os.sep + \"labels\" + os.sep + \"json\")\n",
    "        images =  os.listdir(un_processed_data_path + os.sep + dir + os.sep + \"images\")\n",
    "\n",
    "\n",
    "        coupled_data = list((zip(images,labels)))\n",
    "\n",
    "        mapped_data = {\"dir\":dir, \"couples\":coupled_data}\n",
    "\n",
    "        unp_data.append(mapped_data)\n",
    "    \n",
    "    return unp_data\n",
    "\n",
    "connected_data = connected_data_generator(un_processed_directories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import shutil\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "\n",
    "def generate_data_frame(connected_data, un_processed_data_path, df):\n",
    "\n",
    "    data_append = {            \n",
    "                \"image_name\":[],\n",
    "                \"image_width\":[],\n",
    "                \"image_height\":[],\n",
    "                \"object_class_id\":[],\n",
    "                \"object_class_name\":[],\n",
    "                \"bbox_left\":[],\n",
    "                \"bbox_top\":[],\n",
    "                \"bbox_right\":[],\n",
    "                \"bbox_bottom\":[],\n",
    "            }\n",
    "\n",
    "    for dataindex, data in enumerate(connected_data):\n",
    "        directory = data[\"dir\"]\n",
    "        couples = data['couples']\n",
    "\n",
    "        max_limit = 20\n",
    "\n",
    "        \n",
    "        for idx, coupled_data in enumerate(couples):\n",
    "            if idx < max_limit:\n",
    "                image_file_name = coupled_data[0]\n",
    "                image_label_json = coupled_data[1]\n",
    "    \n",
    "                image_file_path = os.path.join(un_processed_data_path, directory,\"images\", image_file_name)\n",
    "                image_label_path = os.path.join(un_processed_data_path, directory,\"labels\", \"json\", image_label_json)\n",
    "\n",
    "                # read the json data\n",
    "                json_data_frame = pd.read_json(image_label_path)\n",
    "                object_class_name = json_data_frame['ObjectClassName'].values[0]\n",
    "                object_class_id = json_data_frame['ObjectClassId'].values[0]\n",
    "                bbox_left = json_data_frame['Left'].values[0]\n",
    "                bbox_top  = json_data_frame['Top'].values[0]\n",
    "                bbox_right  = json_data_frame['Right'].values[0]\n",
    "                bbox_bottom  = json_data_frame['Bottom'].values[0]\n",
    "    \n",
    "                img = Image.open(image_file_path)\n",
    "        \n",
    "                width = img.width\n",
    "                height = img.height\n",
    "\n",
    "                # data_append['id'].append(idx)\n",
    "                data_append['image_name'].append(directory+\"__\"+image_file_name)\n",
    "                data_append['image_width'].append(width)\n",
    "                data_append['image_height'].append(height)\n",
    "                data_append['object_class_id'].append(object_class_id)\n",
    "                data_append['object_class_name'].append(object_class_name)\n",
    "                data_append['bbox_left'].append(bbox_left)\n",
    "                data_append['bbox_top'].append(bbox_top)\n",
    "                data_append['bbox_right'].append(bbox_right)\n",
    "                data_append['bbox_bottom'].append(bbox_bottom)\n",
    "                \n",
    "                shutil.copy(image_file_path, os.path.join(destination_directory,directory+\"__\"+image_file_name ))   \n",
    "            else:\n",
    "                break    \n",
    "            \n",
    "    \n",
    "    df2  = pd.DataFrame(data_append)\n",
    "    return df2\n",
    "\n",
    "def draw_bouding_box(image_file_path, bbox_left, bbox_top, bbox_right, bbox_bottom):\n",
    "    img = read_image(image_file_path)\n",
    "\n",
    "    bbox = [bbox_left, bbox_top, bbox_right, bbox_bottom]\n",
    "    bbox = torch.tensor(bbox, dtype=torch.int)\n",
    "    print(bbox)\n",
    "    print(bbox.size())\n",
    "    bbox = bbox.unsqueeze(0)\n",
    "    print(bbox.size())\n",
    "\n",
    "            # draw bounding box on the input image\n",
    "    img=draw_bounding_boxes(img, bbox, width=3, colors=(255,255,0))\n",
    "\n",
    "            # transform it to PIL image and display\n",
    "    img = torchvision.transforms.ToPILImage()(img)\n",
    "    img.show()\n",
    "    return img\n",
    "\n",
    "\n",
    "dfc= generate_data_frame(connected_data, un_processed_data_path, df )\n",
    "dfc.head()\n",
    "dfc.to_csv(csv_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
